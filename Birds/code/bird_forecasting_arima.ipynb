{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7ec54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from tqdm import tqdm\n",
    "import matplotlib.animation as ani\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.stattools import adfuller as ADF\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9582955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the columns\n",
    "#pd.set_option('display.max_columns', None)\n",
    "# print all the lines\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b046e",
   "metadata": {},
   "source": [
    "# Forecasting (ARMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728e98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(ts, signif=0.05):\n",
    "    times = -1\n",
    "    p = 1\n",
    "    while (p > signif):\n",
    "        print(times)\n",
    "        times = times + 1\n",
    "        dftest = ADF(ts)\n",
    "        p = dftest[1]\n",
    "        ts = ts.diff().dropna()\n",
    "    return times\n",
    "        \n",
    "def order(train, times):\n",
    "    tmp = []\n",
    "    for p in range(1, 6):\n",
    "        for q in range(5):\n",
    "            try:\n",
    "                tmp.append([ARIMA(train, order=(p, times, q)).fit().bic, p, q])\n",
    "            except:\n",
    "                tmp.append([None, p, q])\n",
    "    tmp = pd.DataFrame(tmp,columns = ['bic', 'p', 'q'])\n",
    "    return tmp[tmp['bic'] == tmp['bic'].min()]\n",
    "    \n",
    "def plot_time_series(ts_1, ts_label_1, ts_2, ts_label_2, title, path):\n",
    "    assert len(ts_1) == len(ts_2)\n",
    "    xs = list(range(0, len(ts_1)))\n",
    "\n",
    "    plt.rcParams['savefig.dpi'] = 300 \n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    \n",
    "    plt.plot(xs, ts_2, c='red', label=ts_label_2, lw = 1)\n",
    "    plt.plot(xs, ts_1, c='green', label=ts_label_1, lw = 1)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "    \n",
    "def comparaison_plot(ts_1, ts_label_1, ts_2, ts_label_2, ts_3, ts_label_3, title):\n",
    "    assert len(ts_1) == len(ts_2)\n",
    "    assert len(ts_2) == len(ts_3)\n",
    "    \n",
    "    xs = list(range(0, len(ts_1)))\n",
    "    \n",
    "    plt.rcParams['savefig.dpi'] = 300 \n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    \n",
    "    plt.plot(xs, ts_2, c='red', label=ts_label_2, lw = 1)\n",
    "    plt.plot(xs, ts_3, c='blue', label=ts_label_3, lw = 1)\n",
    "    plt.plot(xs, ts_1, c='green', label=ts_label_1, lw = 1)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig(path)\n",
    "    plt.show()\n",
    "    \n",
    "def ARIMA_model_loop(data, coef, times, radar): \n",
    "    \n",
    "    train = data[:int(len(data)*coef)]\n",
    "    test = data[int(len(data)*coef):]\n",
    "    par = order(data, times)\n",
    "    # Forecast\n",
    "    start_t = len(train)\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):        \n",
    "        current_t = t + start_t\n",
    "        model = ARIMA(data[:current_t], order=(par['p'], times, par['q']))       \n",
    "        model_fit = model.fit()  \n",
    "        predictions.append(model_fit.forecast().iloc[0])\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions, columns = [radar])\n",
    "    \n",
    "    return predictions \n",
    "\n",
    "def ARIMA_model(data, coef, times):\n",
    "    train = data[:int(len(data)*coef)]\n",
    "    test = data[int(len(data)*coef):]\n",
    "    par = order(data, times)\n",
    "    # Forecast\n",
    "    model = ARIMA(train, order=(par['p'], times, par['q']))       \n",
    "    model_fit = model.fit()  \n",
    "    predictions = pd.DataFrame(model_fit.forecast(len(test)), columns = ['radar'])\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fe08f",
   "metadata": {},
   "source": [
    "## ARIMA with loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34caaf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/time_filled_AR.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7537906890e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_forecasting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dataset/time_filled_AR.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df_forecasting = df_forcasting.drop(['samplingperiod'], axis = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#radar = 'KABX'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/time_filled_AR.csv'"
     ]
    }
   ],
   "source": [
    "df_forecasting = pd.read_csv('../dataset/time_filled_AR.csv')\n",
    "#df_forecasting = df_forcasting.drop(['samplingperiod'], axis = 1)\n",
    "coef = 0.5\n",
    "#radar = 'KABX' \n",
    "pred = pd.DataFrame()\n",
    "for radar in tqdm(df_forecasting.columns.drop('samplingperiod')):\n",
    "\n",
    "    times = adf_test(df_forecasting[radar])\n",
    "    pred[radar] = ARIMA_model_loop(df_forecasting[radar], coef, times, radar)\n",
    "    print(pred)\n",
    "    #plot_time_series(ts_1=pred[radar], ts_label_1='ARIMA Model', ts_2=df_forecasting[radar], ts_label_2='True data', title='ARIMA predictions vs. ground truth of %s'%radar, path = '../figures/bird/%s.png'%radar)\n",
    "\n",
    "pred.to_csv('../dataset/pred_ARIMA.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ff084",
   "metadata": {},
   "source": [
    "## ARIMA with log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736b2a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/time_filled_AR.csv')\n",
    "#print(data.isnull().sum())\n",
    "#df_forecasting = df_forcasting.drop(['samplingperiod'], axis = 1)\n",
    "\n",
    "df_forecasting = np.log10(data[data.columns.drop('samplingperiod')]+1)\n",
    "coef = 0.5\n",
    "pred = pd.DataFrame()\n",
    "#radar = 'KAPX' \n",
    "#print(df_forecasting[radar])\n",
    "for radar in tqdm(df_forecasting.columns):\n",
    "    \n",
    "    times = adf_test(df_forecasting[radar])\n",
    "    pred[radar] = np.power(10, ARIMA_model_loop(df_forecasting[radar], coef, times, radar))-1\n",
    "    #plot_time_series(ts_1=pred[radar], ts_label_1='ARIMA Model', ts_2=data[radar], ts_label_2='True data', title='ARIMA predictions vs. ground truth of %s'%radar, path = '../figures/bird/%s.png'%radar)\n",
    "    print(pred)\n",
    "    \n",
    "pred.to_csv('../dataset/pred_log.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e0458",
   "metadata": {},
   "source": [
    "## ARIMA without loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db53a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_forecasting = pd.read_csv('../dataset/time_filled_AR.csv')\n",
    "coef = 0.5\n",
    "pred = pd.DataFrame()\n",
    "#radar = 'KABX'\n",
    "for radar in tqdm(df_forecasting.columns.drop('samplingperiod')):\n",
    "    \n",
    "    times = adf_test(df_forecasting[radar])\n",
    "    pred[radar] = ARIMA_model(df_forecasting[radar], coef, times)\n",
    "    #plot_time_series(ts_1=pred[radar], ts_label_1='ARIMA Model', ts_2=time.radar[radar], ts_label_2='True data', title='ARIMA predictions vs. ground truth of %s'%radar, path = '../figures/bird/%s.png'%radar)\n",
    "    print(pred)\n",
    "    \n",
    "pred.to_csv('../dataset/pred_ARIMA_noloop.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441c2bf",
   "metadata": {},
   "source": [
    "## Comparison between three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_plot(ts_1 = pred[int(len(pred)*coef)-2:], ts_label_1 = 'ARIMA loop', ts_2 = time.radar[radar][int(len(pred)*coef)-2:], \n",
    "                 ts_label_2 = 'true data', ts_3 = pred1[int(len(pred)*coef)-2:], ts_label_3 = 'ARIMA', \n",
    "                 title = 'comparison of ARIMA and ARIMA loop')\n",
    "comparaison_plot(ts_1 = pred, ts_label_1 = 'ARIMA loop', ts_2 = time.radar[radar], \n",
    "                 ts_label_2 = 'true data', ts_3 = pred1, ts_label_3 = 'ARIMA', \n",
    "                 title = 'comparison of ARIMA and ARIMA loop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c57d0",
   "metadata": {},
   "source": [
    "# Forecasting (VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv('../dataset/time_series.csv')\n",
    "time.radar = pd.read_csv('../dataset/time_filled_ARIMA.csv')\n",
    "coef = 0.7\n",
    "#apply adf test on the series\n",
    "test = time.radar[int(coef*(len(time.radar))):]\n",
    "train = time.radar[:int(coef*(len(time.radar)))]\n",
    "predictions = train\n",
    "#start_t = len(train)\n",
    "#for t_i in tqdm(range(len(test))):\n",
    "#current_t = t_i + start_t\n",
    "model = VAR(train)#time.radar[:current_t])\n",
    "model_fit = model.fit()\n",
    "prediction = model_fit.forecast(model_fit.y, steps=len(test))\n",
    "prediction = pd.DataFrame(prediction, columns = time.radar.columns)\n",
    "predictions = pd.concat([predictions, prediction], axis = 0)\n",
    "predictions.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for radar in predictions.columns:\n",
    "    plot_time_series(ts_1=predictions[radar], ts_label_1='VAR prediction', ts_2=time.radar[radar], ts_label_2='True data', title='VAR predictions vs. ground truth of %s'%radar, path = '../figures/bird/VAR/%s.png'%radar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('../dataset/pred_var.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e2b79",
   "metadata": {},
   "source": [
    "# Forecasting(ARMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_armax(train, data_ex, times):\n",
    "    tmp = []\n",
    "    for p in tqdm(range(1, 6)):\n",
    "        for q in tqdm(range(5)):\n",
    "            try:\n",
    "                tmp.append([ARIMA(train, exog = data_ex, order=(p, times, q)).fit().bic, p, q])\n",
    "            except:\n",
    "                tmp.append([None, p, q])\n",
    "    tmp = pd.DataFrame(tmp,columns = ['bic', 'p', 'q'])\n",
    "    return tmp[tmp['bic'] == tmp['bic'].min()]\n",
    "\n",
    "def ARMAX_model(data, data_ex, coef, times):\n",
    "\n",
    "    train = data[:int(len(data)*coef)]\n",
    "    test = data[int(len(data)*coef):]\n",
    "    par = order_armax(train, data_ex[:int(len(data)*coef)], times)\n",
    "    # Forecast\n",
    "    start_t = len(train)\n",
    "    predictions = list()\n",
    "    for t in range(len(test)): \n",
    "        \n",
    "        current_t = t + start_t\n",
    "        model = ARIMA(data[:current_t], exog = data_ex[:current_t], order=(par['p'], times, par['q']))       \n",
    "        model_fit = model.fit()  \n",
    "        \n",
    "        print(model_fit.predict())\n",
    "        #print(model_fit.summary())\n",
    "        model_fit.plot_diagnostics(figsize=(12, 12))\n",
    "\n",
    "        #print(model_fit.forecast())\n",
    "        predictions.append(model_fit.predict())\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions = pd.concat([train, predictions], axis = 0)\n",
    "    predictions.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return predictions \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv('../dataset/radar/time_series.csv')\n",
    "time.radar = pd.read_csv('../dataset/radar/time_filled_ARIMA.csv')\n",
    "data_w = pd.read_csv('../dataset/radar/weather_information.csv')\n",
    "radars = time.radar.columns\n",
    "coef = 0.5\n",
    "times = 0\n",
    "weather1=['uwind','vwind','air','pressure.sfc','relative.humidity','ordinal.date', \n",
    "         'omega', 'total.cloud.cover', 'visibility', 'albedo', 'acc.total.precip', 'msl.pressure','cape','snow.cover']\n",
    "#for radar in radars:\n",
    "radar = 'KABX'\n",
    "print(len(time.radar[radar]))\n",
    "print(len(data_w[data_w['radar_id'] == radar][weather1]))\n",
    "pred = ARMAX_model(time.radar[radar], data_w[data_w['radar_id'] == radar][weather1], coef, times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9fce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(ts_1=pred, ts_label_1='ARIMA Model', ts_2=data.density[data.density['radar_id'] == radar]['linear_eta'], ts_label_2='True data', title='ARIMA predictions vs. ground truth of %s'%radar, path = '../figures/bird/%s.png'%radar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61522042",
   "metadata": {},
   "source": [
    "# Forecasting (VARMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VARMAX_model(data, coef):\n",
    "    train = data[:int(coef*(len(data)))]\n",
    "    valid = data[int(coef*(len(data))):]\n",
    "    \n",
    "\n",
    "    tmp = []\n",
    "    for p in tqdm(range(1, 6)):\n",
    "        for q in tqdm(range(5)):\n",
    "            #try:\n",
    "            tmp.append([VARMAX(train, order = (p,q)).fit().bic, p, q])\n",
    "            #    print(tmp)\n",
    "            #except:\n",
    "            #    tmp.append([None, p, q])\n",
    "    tmp = pd.DataFrame(tmp, columns = ['bic', 'p', 'q'])\n",
    "    print(tmp)\n",
    "    order = tmp[tmp['bic'] == tmp['bic'].min()]\n",
    "    print(order)\n",
    "\n",
    "    try: \n",
    "        predictions = train\n",
    "        start_t = len(train)\n",
    "        for t_i in tqdm(range(len(valid))):\n",
    "            current_t = t_i + start_t\n",
    "            model = VARMAX(data[:current_t], order = (order['p'], order['q']))\n",
    "            fitted_model = model.fit()\n",
    "            prediction = fitted_model.forecast()\n",
    "            prediction = pd.DataFrame(prediction)\n",
    "            predictions = pd.concat([predictions, prediction], axis = 0)\n",
    "\n",
    "        #plot_time_series(ts_1 = prediction_chamber, ts_label_1 = 'VARMA Model', ts_2 = valid['chamber'], ts_label_2 = 'Close', title = 'VARMA predictions vs. ground truth')\n",
    "        #plot_time_series(ts_1 = prediction['location_x'], ts_label_1 = 'VARMA Model', ts_2 = data['location_x'], ts_label_2 = 'Close', title = 'VARMA predictions vs. ground truth of location x', path = '../figures/insect/%i/x1.png'%num_ant)\n",
    "        #plot_time_series(ts_1 = prediction['location_y'], ts_label_1 = 'VARMA Model', ts_2 = data['location_y'], ts_label_2 = 'Close', title = 'VARMA predictions vs. ground truth of location y', path = '../figures/insect/%i/y1.png'%num_ant)\n",
    "\n",
    "        #prediction_c = num_chamber(prediction['location_x'], prediction['location_y'])\n",
    "        #prediction_c = pd.DataFrame(prediction_c, columns = ['%i'%num_ant])\n",
    "        #prediction_c.to_csv('../dataset/insect/ant/predictions/prediction_%i.csv'%num_ant, index = False)\n",
    "    except Exception as reason:\n",
    "        print('%i'%num_ant, reason)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv('../dataset/radar/time_series.csv')\n",
    "time.radar = pd.read_csv('../dataset/radar/time_filled_ARIMA.csv')\n",
    "coef = 0.7\n",
    "#for radar in time.radar.columns:\n",
    "pred = VARMAX_model(time.radar.values, coef)\n",
    "pred.to_csv('../dataset/radar/pred_varmax.csv', index = False)\n",
    "#plot_time_series(ts_1=pred, ts_label_1='ARIMA Model', ts_2=time.radar[radar], ts_label_2='True data', title='ARIMA predictions vs. ground truth', path = '../figures/bird/%s.png'%radar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acaf4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
